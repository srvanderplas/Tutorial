---
title: "A Short Overview of Statistics"
format: 
  revealjs:
    theme: [default, unl.scss]
    includes:
      in_header: pres-header.html
    logo: image/N.svg
editor: visual
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
# remotes::install_github("mitchelloharawild/icons")
library(icons)
```

## What is Statistics?

> The science of developing and studying methods for collecting, analyzing, interpreting, and presenting empirical data

::: {.columns style="font-size:smaller"}
::: {.column width="80%"}
-   How should I conduct my experiment?
-   What is the best way to test my hypothesis?
-   What is the true value of \_\_\_\_\
    (and how precisely do I know that value)?
-   What does my experiment/sample tell me about my data?
-   What is the future value of \_\_\_\_ given what I know now?
:::

::: {.column width="20%"}
![](image/Ruler-fuzzball.png)
:::
:::

## Statistical Tasks {.center}

**Description**: What does the data say?

![](image/histogram-sample-stats.png){width="40%" fig-align="center"}

## Statistical Tasks {.center}

**Experimental Design**: What's the best way to collect data?

![](image/wizard-list.png){width="50%" fig-align="center"}

## Statistical Tasks {.center}

**Inference**: What does the data tell us (about the population)?

![](image/sample-population.png){width="50%" fig-align="center"}

## Statistical Tasks {.center}

**Prediction**: What will happen next?

![](image/crystal-ball-fuzzball.png){width="50%" fig-align="center"}

## An Historical Example {.center .middle}

### The Logic of Hypothesis Testing

![](image/tea-tasting-fuzzballs.png){fig-align="center" width="100%"}

Can someone tell whether tea or milk is added first to a cup?

-   4 cups of tea with milk first `r icon_style(fontawesome("coffee"), fill="#d2b48c")`, 4 cups of tea with tea first `r icon_style(fontawesome("coffee"), fill="#835C3B")`

-   Randomize the order

-   Test the cups and make predictions for all 8 cups

::: {.emph .cerulean}
What is the probability that someone gets all 8 correct?
:::

## A Lady Tasting Tea

-   If the 4 milk-first cups `r icon_style(fontawesome("coffee"), fill="#d2b48c")` are correctly identified, so are the 4 tea-first cups `r icon_style(fontawesome("coffee"), fill="#835C3B")`

-   If we assume the taster is just guessing, we could just as easily flip 4 coins

![](https://media2.giphy.com/media/C3Zq724SuDX0I/giphy.gif?cid=790b76112e6121b7619d267c8566ceebfb533213d14ece53&rid=giphy.gif&ct=g){width="50%" fig-align="center"}

## A Lady Tasting Tea

::: {.emph .cerulean}
Statistical evaluation
:::

-   Null hypothesis: Taster is guessing

    -   If our experimental results are likely to occur by random chance, we can't really say whether the taster is guessing or not\
        `r fontawesome("share")` We fail to reject the null hypothesis

    -   If our experimental results are not likely to occur by random chance, we may decide it's more likely that there is another explanation... the taster knows their stuff!

## Try it out! {background-color="#c7c8ca"}

Go to [<https://shiny.srvanderplas.com/APL>]{.emph} and start with the Tea Tasting tab.

-   What effect does the \# simulations have on the results?

-   What effect does the \# test cups have on the results?

    -   [Assuming the number of observed cups is the same as the number of test cups]{style="font-size:smaller;"}
    -   [Assuming the number of observed cups is less than the number of test cups]{style="font-size:smaller;"}

::: aside
Another link to the same applet is [<https://srvanderplas.shinyapps.io/UNL-APL-workshop/>]{.emph}
:::

## Hypothesis Testing Logic {.smaller}

::: columns
::: {.column width="50%"}
1.  Run an experiment and generate an observed value

2.  Simulate a large number of experiments under random chance (the null hypothesis)

3.  Compare the observed value to the results of the simulated experiments

4.  Decide whether the observed value is plausible under random chance, or it is more likely that the results would happen if the null hypothesis is wrong
:::

::: {.column width="50%"}
![](image/simulation-logic.svg)
:::
:::

## Theory-based Statistics {.smaller}

::: columns
::: {.column width="50%"}
1.  Run an experiment and generate a test statistic (t, z, F, $\chi^2$)

2.  Compare the observed value to the theoretical distribution

3.  Decide whether the observed value is plausible under random chance, or it is more likely that the results would happen if the null hypothesis is wrong
:::

::: {.column width="50%"}
![](image/theory-logic.svg)
:::
:::

## Try it out {.smaller background-color="#c7c8ca"}

Go to [<https://shiny.srvanderplas.com/APL>]{.emph} and start with the Distributions tab.

-   What changes when you change distribution?

-   How many samples do you need for the simulation histogram to look similar to the theoretical distribution?

-   What effect does setting your observed value to be larger have on the p-value?\
    Note: At this point, we are doing tests examining values greater than the observed value. This will obviously not always hold true.

-   How different is the simulation p-value from the theoretical p-value? Does this change when you increase the number of samples?

## Statistical Test Logic

-   [Goal:]{.emph .cerulean} Are the experiment results are compatible with the null hypothesis?

-   if the region that is "more extreme" than the observed value is very small, then the experimental results are surprising

    -   This suggests the null hypothesis might not be reliable
    -   Reject $H_0$ in favor of the alternative

## Statistical Test Logic

![](image/p-value-logic.svg)

## Statistical Test Logic

-   the region that is "more extreme" than the observed value is summarized as the p-value -- the area of that region.

    -   p-values lower than $\alpha = 0.05$, a pre-specified cutoff are considered "statistically significant"\
        that is, they should lead to a rejection of the null hypothesis

![](image/p-value.png){fig-align="center" width="50%"}

## Two Sided Tests

-   If we don't know/care whether $x < a$ or $x > a$, we use a **two-sided test**

![](image/two-sided-test-slide.png){fig-align="center" width="100%"}

You can experiment with two-sided tests here:

[[https://shiny.srvanderplas.com/APL/](https://shiny.srvanderplas.com/APL)]{.emph} and click on "One Continuous Variable"

## Confidence Intervals

-   Another way to use statistics is to get a range of "plausible" values based on the estimate + variability

-   This is called a **confidence interval**

![](image/confidence-interval-best-est-uncertanty.svg){width="50%" fig-align="center"}

## Confidence Intervals

-   Every confidence interval has a "level" of $1-\alpha$, just like every hypothesis test has a significance level $\alpha$

-   Confidence intervals with higher levels (e.g. .99 instead of .95) are wider

-   Interval width depends on

    -   sample size
    -   variability
    -   confidence level

-   A CI of (A, B) is read as "We are 95% confident that the true value of \_\_\_\_\_\_\_\_\_ lies between A and B"

# Experimental Design

## One Categorical Variable

-   Statistic: \# Successes (out of \# Trials)

-   Simulation method: Flip coins $(p = 0.5)$, weighted spinners $(p\neq 0.5)$

-   Theoretical distribution: Binomial

[[https://shiny.srvanderplas.com/APL/](https://shiny.srvanderplas.com/APL)]{.emph} and click on "One Categorical Variable"

## One Continuous Variable

-   Statistic: $\displaystyle t = \frac{\overline x - \mu}{s/\sqrt{n}}$ where
    -   [$\overline x$ is the sample mean,]{style="font-size:smaller;"}
    -   [$s$ is the sample standard deviation,]{style="font-size:smaller"}
    -   [$\mu$ is the hypothesized mean, and]{style="font-size:smaller"}
    -   [$n$ is the sample size]{style="font-size:smaller"}
-   Simulation method: none
-   Theoretical distribution: $t$ with $n-1$ degrees of freedom

[[https://shiny.srvanderplas.com/APL/](https://shiny.srvanderplas.com/APL)]{.emph} and click on "One Continuous Variable"

## Two-group Tests

-   Categorical variable: Group 1 or Group 2?

-   Continuous variable: Some measurement

-   Statistic: $\overline x_1 - \overline x_2$

-   Simulation method: shuffle group labels

-   Theoretical distribution: $t$\
    (degrees of freedom are a bit complicated)

[[https://shiny.srvanderplas.com/APL/](https://shiny.srvanderplas.com/APL)]{.emph} and click on "Categorical + Continuous Variables"

## Two-group Tests

![A two-sample experiment randomly divides up a sample of experimental units into two groups and calculates the sample mean for each group.](image/unpaired-test-1.png)

## Two-group Tests

![A two-sample experiment randomly divides up a sample of experimental units into two groups and calculates the sample mean for each group.](image/unpaired-test-2.png)

We compare $\overline{X}_A$ and $\overline {X}_B$: $\overline{X}_A - \overline{X}_B$.

The standard deviation of $\overline{X}_A - \overline{X}_B$ requires calculation: Use a two-sample test.

## Repeated Measures

![](image/repeated-measures-1.png)

## Repeated Measures

![](image/repeated-measures-2.png)

## Matched Pairs

![](image/matched-pairs-1.png)

## Matched Pairs

![](image/matched-pairs-2.png)

## Matched Pairs

![](image/matched-pairs-3.png)

## Matched Pairs

![](image/matched-pairs-4.png)

## Analysis of Variance

::: {.emph .cerulean}
Used for multiple groups
:::

Suppose we have a group of schoolchildren separated by grade, and we want to examine the relationship between grade and height.

![](image/anova-class.png){width="100%"}

## Analysis of Variance

![](image/anova-class-means.png){width="100%"}

If height is important, students in a [single grade]{.emph .red} should be [more similar]{.emph .cerulean} than students across different grades.

## Analysis of Variance

[Goal:]{.emph .cerulean} determine similarity within groups

-   **within-groups sum-of-squares**\
    Square the deviations from the group mean and add them up

-   **between-groups sum-of-squares**\
    Sum of squared differences of the class average and the overall average for each student

![](image/anova-class-deviations.png){width="100%"}

## Analysis of Variance {.smaller}

Results from ANOVA are shown in tables like this:

```{r, include = F}
library(dplyr)
library(tibble)

data <- tibble(group = rep(1:3, each = 6), 
       groupavg = rep(c(41, 43, 47), each = 6),
       dev = c(0, 3, -1, 0, -1, -1, -1, -1, 2, -2, 1, 1, 0, 0, 0, 0, -2, 2))

data <- mutate(data, height = groupavg + dev, grade = factor(group))

anova(lm(height ~ grade, data = data))
```

```{r, echo = F}
options(knitr.kable.NA = '') 
as_tibble(anova(lm(height ~ grade, data = data))) %>%
  mutate(Factor = c("grade", "Residuals")) %>%
  select(Factor, everything()) %>%
  bind_rows(tibble(Factor = "Total", Df = 17, `Sum Sq` = 144, `Mean Sq` = NA, `F value` = NA, `Pr(>F)` = NA)) %>%
  knitr::kable()
```

The F-value is the statistic, and is compared to an F(df1, df2) distribution - in this case, F(2, 15) to get a p-value.

## Two Continuous Variables

![We want to know if there is a linear association between x and y](image/linear-trend.svg)

## Two Continuous Variables

![If the slope of the line is nonzero, there is a linear association](image/linear-regression-1.svg)

## Two Continuous Variables

![We need to test whether that slope is significantly different from 0](image/linear-regression-diff-lines.svg)

## Two Continuous Variables

-   Continuous variables: $x$ and $y$

-   Statistic: $a$, the sample slope

-   Simulation method: shuffle values of $y$ relative to $x$

-   Theoretical distribution: $t_{n-2}$, where $n$ is the number of observations
