[
  {
    "objectID": "Extension/2022-Extension-REU.html",
    "href": "Extension/2022-Extension-REU.html",
    "title": "Statistics Primer",
    "section": "",
    "text": "Statistics is the science concerned with developing and studying methods for collecting, analyzing, interpreting, and presenting empirical data.\nStatistics answers questions like\n\nHow should I conduct experiments?\nWhat is the best way to test my hypothesis?\nWhat is the true value of ___ and how precisely do I know that value?\nWhat does my experiment/sample value tell me about my data?\nWhat the value of ___ will be in the (near) future\n\nStatistics concerns itself with several different (but related) tasks:\n\n\n\n\n\n\nDescription: What does the data say? | Inference: What does the data tell us (about the population)? | | |  | \n\n\nExperimental Design: What’s the best way to collect data? | Prediction: What will happen next? | | |  | \n\n\n\n\n\n\nSir Ronald Fisher once had a conversation with a woman who claimed to be able to tell whether the tea or milk was added first to a cup. Fisher, being interested in probability, decided to test this woman’s claim empirically by presenting her with 8 randomly ordered cups of tea - 4 with milk added first, and 4 with tea added first. The women was then supposed to select 4 cups prepared with one method, but is allowed to directly compare each cup (e.g. tasting each cup sequentially, or in pairs).\n\nThe lady identified each cup correctly. Do we believe that this could happen by random chance alone?1\n\n\n\nNull Hypothesis (what we are hoping to disprove):\nThere is no observable difference between the two methods of preparing tea (any success is by chance alone).\nAlternative Hypothesis (if random chance isn’t the reason, then what?):\nThere is an observable difference between the two methods of preparing tea, that is, the woman can actually detect via taste which cups were prepared using either method.\n\nIf the results we observed are due to random chance alone, how common would it be to get 8/8 correct?\n\n\n\n\nFlip a coin 4 times to represent the 4 cups identified as containing tea with milk added first. Heads corresponds to a correct decision, Tails to an incorrect decision.\nRecord the number of successful selections\nRepeat 100 times to generate a distribution of results under the null hypothesis – that is, what our results would look like if the lady is just guessing.\n\n\n\n\n\n\nSimulated results (left), and simulated results evaluated in light of our observed data.\n\n\n\n\n\n\n\nSimulated results (left), and simulated results evaluated in light of our observed data.\n\n\n\n\nYou can play with different configurations of the tea tasting scenario here or here (two links to different servers hosting the same application).\n\n\n\nOur simulation shows that under random chance, it appears that our tea taster would be expected to identify all of the cups correctly (corresponding to HHHH) 4/100 = 0.04 times.\n\n\n\n\n\n\nNote\n\n\n\n0.04 in this example corresponds to our p-value - the probability under the null hypothesis of observing the results from our experiment.\n\n\n0.04 is a fairly low value, so we might say that we don’t believe that the results are sufficiently likely under our null hypothesis. In this case, the probability of observing the results under the null hypothesis is low, so we might instead conclude that the alternative hypothesis seems more reasonable – that is, it is more likely that the null hypothesis is wrong. So, we might instead conclude that because our p-value is so low, that is, that we are unlikely to observe results this extreme under random chance, that instead we believe that the lady is not guessing and can actually detect the difference in tea prepared in different ways. We reject the null hypothesis and conclude that the alternative is more likely.\nNow, in this example, we have a relatively low sample size – which means that it is hard for us to find evidence too much stronger than what our simulation provided for us. In many situations in science, however, we may require stronger evidence that the null hypothesis is unlikely to generate results that we have observed – corresponding to requiring a p-value that is lower than 0.05. The correct threshold value (“alpha”) for rejecting a null hypothesis differs by discipline (physics may use values like \\(10^{-6}\\)) and by the consequences of the results (medical trials may require small p-values, while studies looking for avenues to explore may use higher p-values.)\n\n\n\nThe simulation method described above for evaluating the probability of observing the evidence under the null hypothesis relies on significant manual simulation or outsourcing that work to a computer. The results are not guaranteed to be the same every time, and before computers were common, the manual simulation approach was often too tedious to use regularly. Thus, probability distributions describing the results mathematically were used instead.\n\n\n\nSimulated distributions approximate the theoretical distribution, but connect more clearly to real-world ideas.\n\n\nNo matter what distribution the researcher uses to compare to, the basic idea of theory-based statistics is the same: we look for evidence that our result is (or is not) likely under the null hypothesis. If the result is likely under the null, then we can’t say anything – we can’t disprove the idea that the results are due to chance. If the result isn’t likely under the null, then we reject the null hypothesis and say the alternative is more likely.\nIn theory-based tests, this evidence is usually in the form of a __-value, where the blank is the name of the distribution (commonly, \\(z\\), \\(t\\), \\(F\\), \\(\\chi^2\\)).\n\n\n\nThe same process used in simulated distributions works in theory-based distributions.\n\n\nYou can play with different simulations and distributions here or here (two links to different servers hosting the same application). Use the Distributions tab.\n\n\n\nThe p-value is the probability of observing the data we saw under the null hypothesis \\(H_0\\). A p-value is the area under the reference distribution where values are as or more extreme than the hypothesized value.\n\nIf the p-value is low (\\(p &lt; \\alpha\\), where \\(\\alpha = 0.05, 0.01\\), or another pre-specified value) then we know that it is relatively unlikely to observe our data under \\(H_0\\)… which means that it is more likely that \\(H_0\\) is false and \\(H_A\\) is true.\nWhen p-values are low, we reject \\(H_0\\) and conclude that \\(H_A\\) is more likely.\n\nNot all alternative hypotheses are one sided, e.g. \\(x &gt; a\\). Some hypotheses are two sided - \\(H_0: x = a\\) and \\(H_A: x \\neq a\\). When we have a two-sided hypothesis, we have two areas of our distribution that contribute to the p-value.\n\n\n\n\nSometimes, we don’t want to test whether a parameter is equal to a specific value - instead, we might want to know what that value is (or at least, a range of possible values for that parameter).\nIn this case, we construct a confidence interval - a set of plausible values for the parameter.\nWe can think of a confidence interval as our best estimate of the parameter value + uncertainty.\n\n\n\nConfidence intervals are a range of values around the central estimate obtained from the sample data\n\n\nConfidence intervals, like hypothesis tests, are conducted based on a parameter \\(\\alpha\\) representing the acceptable level of error. If we want to be 95% confident in our estimate, our interval will be wider than if we want to be 90% confident in our estimate – we have to include more values to get a wider interval.\n\n\n\nMany studies have a design which is more complicated than the simple examples shown in the previous section. However, all of these designs use the same statistical principles - they may just be applied in different ways.\nWhat follows is a brief description and depiction of how these different experimental designs work in practice. Focus primarily on the way the experiments are set up – in the end, there is always a test statistic computed from the sample mean(s) and variance(s) which is compared to a distribution, as described above.\n\n\n\n\nIn one-sample tests of categorical variables, we typically want to know whether the proportion of successes (the quantity we’re interested in) is equal to a specific value (that is, \\(\\pi = 0.5\\) or something of that sort). Our population parameter, \\(\\pi\\), represents the unknown population quantity, and our sample statistic, \\(\\hat p\\), represents what we know about the value of \\(\\pi\\).\nIn these tests, our null hypothesis is that \\(\\pi = a\\), where a is chosen relative to the problem. Often, \\(a\\) is equal to 0.5, because usually that corresponds to random chance.\nWhen simulating these experiments, we will often use a coin flip (for random chance) or a spinner (for other values of \\(\\pi\\)) to generate data.\nYou can play with different one sample categorical tests here or here (two links to different servers hosting the same application). Use the One Categorical Variable tab.\n\n\n\nOne-sample continuous variable experiments cannot be simulated because we do not usually know the characteristics of the population we’re trying to predict from. Instead, we use theory-based tests for continuous one-sample data.\nYou can play with different one sample continuous tests here or here (two links to different servers hosting the same application). Use the One Continuous Variable tab.\n\n\n\n\n\nIn a two-sample test, there are two groups of participants which are assigned different treatments. The goal is to see how the two treatments differ. Because there are two groups, the mathematical formula for calculating the standardized statistic is slightly more complicated (because the variability of \\(\\overline{X}_A - \\overline{X}_B\\) is a bit more complicated), but in the end that statistic is compared to a similar reference distribution.\n \nYou can play with different two sample categorical tests here or here (two links to different servers hosting the same application). Use the Categorical + Continuous Variable tab.\n\n\n\nIn a variation on this theme, in some cases, we may want to compare two treatments, but we may design the experiment to reduce variability using either repeated measures or matched pairs.\nA repeated measures study requires each participant to experience both treatments in the experiment.\n\n\n\nIn a repeated measures study, the same individuals see both treatment A and treatment B; this way, each individual serves as their own control\n\n\nSometimes, it is not ethical or feasible to give the same individual both treatments – for instance, we cannot ethically or logistically assign mothers to breastfeed or formula feed with the same baby – and so instead, we must create pairs of individuals who are similar.\n\n\n\nIn a matched pairs study, we use covariates to match individuals and then assign each individual in a pair to a single treatment. Matched pairs studies reduce variability, but not as much as repeated measures studies\n\n\nYou can play with different matched-pairs and repeated-measures studies here or here (two links to different servers hosting the same application). Use the One Continuous Variable tab, and the difference between your matched pairs or repeated measures as your observation.\n\n\n\n\nIn other cases, we may be more interested in sources of variability in the data.\n\n\n\nSuppose we have a group of elementary school children, separated by grade. We want to know if grade is a good predictor of the children’s height.\n\n\nIf a variable is important, then it should account for more variability in the data than the overall variability between two observations. In this example, that means that children within a grade should be more similar than children who are from different grades.\n\n\n\nTo get this information, for each group we calculate the group mean\n\n\n\n\n\nThen, for each individual, we calculate the deviation from the group mean\n\n\nANOVA models are sometimes shown in tables like this:\n\n\n\n\n\nFactor\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\ngrade\n2\n112\n56.000000\n26.25\n1.26e-05\n\n\nResiduals\n15\n32\n2.133333\n\n\n\n\nTotal\n17\n144\n\n\n\n\n\n\n\n\nThe overall statistic we calculate is the ratio of the sum-of-squares within groups to the sum-of-squares between groups. The mathematical details of this aren’t that important here, unless they make the process easier to understand.\nBetween group SS: \\(6 * (43.77 - 41)^2 + 6* (43 - 43.77)^2 + 6 * (47 - 43.77)^2 = 42.77 + 2.69 + 66.53 = 112\\)\nWithin group SS: \\[\\left(0^2 + 3^2 + (-1)^2 + 0^2 + (-1)^2 + (-1)^2\\right) + \\\\\n\\left((-1)^2 + (-1)^2 + 2^2 + (-2)^2 + 1^2 + 1^2\\right) + \\\\\n\\left(0^2 + 0^2 + 0^2 + 0^2 + (-2)^2 + 2^2\\right) = 32\\]\nSo by adding the group variable, we reduce our total error from 144 (112 + 32) to 32. Not bad! Put another way, our group variable explains some 77% of the overall variability in the data.\nANOVA models calculate out an F-statistic which is compared to an F-distribution. This F-statistic is calculated as the ratio of the Mean Sq. for each group - the sum of squared errors for each group (between, within) divided by the degrees of freedom (the number of observations - 1). In this case, our F value (with 2, 15 degrees of freedom) is 26.25. This corresponds to a p-value of 0.00001262 – so the chances of observing something this significant when there is in fact no difference between groups is very low.\n\n\n\n\n\nIt is clear that 26.25 is very much in the tails of the F(2, 15) distribution, which explains the extremely low p-value.\n\n\n\n\n\n\n\n\n\n\n\nTwo continuous variables may have a linear relationship\n\n\nIt’s fairly common in science to have two continuous quantitative variables – for instance, height and weight, or fertilizer applied and yield. When we have data like this, we use linear regression to fit a regression line to the data. This line minimizes the errors in \\(y\\), and is sometimes called the least squares regression line.\n\n\n\nWe estimate the linear relationship using the least-squares regression line \\(\\hat{y} = a \\cdot x + b\\), where \\(a\\) is the slope of the line and \\(b\\) is the y-intercept. \\(\\hat y\\) is the predicted value of y at a given value of \\(x\\)\n\n\nGenerally, though, our data are not fixed: they are the result of sampling. If this is the case, then we know that a different sample may provide a different result. Thus, we know that any estimates \\(a\\) and \\(b\\) have variability that directly results from how we collected the data.\n\n\n\nIf we have a different sample, we may get a different regression line – which means \\(a\\) and \\(b\\) have variability (and a corresponding distribution)\n\n\nAs a result, we generally have a distribution of values corresponding to \\(a\\) and a similar distribution of values corresponding to \\(b\\). Because our data are the result of a random sample, we can analyze the least squares regression coefficients using statistical techniques.\nWe may want to test hypotheses about \\(a\\) such as “Is there a relationship between \\(x\\) and \\(y\\)?” (This doesn’t mention \\(a\\), but if there is no relationship between \\(x\\) and \\(y\\), then \\(a\\) would be 0, so implicitly, we’re asking whether \\(a = 0\\).) Typically, scientists aren’t as interested in the value of \\(b\\).\nWe can test these hypotheses using simulation by arranging our data as if there is no relationship between \\(x\\) and \\(y\\) - that is, by shuffling our \\(y\\) data to correspond to a random \\(x\\) value in the dataset. Then, we would fit a new regression line and record the value of \\(a^\\ast\\) (the simulated \\(a\\)).\nJust like before, when we shuffled data or labels, we generate a distribution of \\(a^\\ast\\) under the null hypothesis and compare our observed value to that distribution, counting up the number of values which are more extreme.",
    "crumbs": [
      "Statistics Primer"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU.html#what-is-statistics",
    "href": "Extension/2022-Extension-REU.html#what-is-statistics",
    "title": "Statistics Primer",
    "section": "",
    "text": "Statistics is the science concerned with developing and studying methods for collecting, analyzing, interpreting, and presenting empirical data.\nStatistics answers questions like\n\nHow should I conduct experiments?\nWhat is the best way to test my hypothesis?\nWhat is the true value of ___ and how precisely do I know that value?\nWhat does my experiment/sample value tell me about my data?\nWhat the value of ___ will be in the (near) future\n\nStatistics concerns itself with several different (but related) tasks:\n\n\n\n\n\n\nDescription: What does the data say? | Inference: What does the data tell us (about the population)? | | |  | \n\n\nExperimental Design: What’s the best way to collect data? | Prediction: What will happen next? | | |  |",
    "crumbs": [
      "Statistics Primer"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU.html#an-historical-example-the-logic-of-statistical-hypothesis-testing",
    "href": "Extension/2022-Extension-REU.html#an-historical-example-the-logic-of-statistical-hypothesis-testing",
    "title": "Statistics Primer",
    "section": "",
    "text": "Sir Ronald Fisher once had a conversation with a woman who claimed to be able to tell whether the tea or milk was added first to a cup. Fisher, being interested in probability, decided to test this woman’s claim empirically by presenting her with 8 randomly ordered cups of tea - 4 with milk added first, and 4 with tea added first. The women was then supposed to select 4 cups prepared with one method, but is allowed to directly compare each cup (e.g. tasting each cup sequentially, or in pairs).\n\nThe lady identified each cup correctly. Do we believe that this could happen by random chance alone?1\n\n\n\nNull Hypothesis (what we are hoping to disprove):\nThere is no observable difference between the two methods of preparing tea (any success is by chance alone).\nAlternative Hypothesis (if random chance isn’t the reason, then what?):\nThere is an observable difference between the two methods of preparing tea, that is, the woman can actually detect via taste which cups were prepared using either method.\n\nIf the results we observed are due to random chance alone, how common would it be to get 8/8 correct?\n\n\n\n\nFlip a coin 4 times to represent the 4 cups identified as containing tea with milk added first. Heads corresponds to a correct decision, Tails to an incorrect decision.\nRecord the number of successful selections\nRepeat 100 times to generate a distribution of results under the null hypothesis – that is, what our results would look like if the lady is just guessing.\n\n\n\n\n\n\nSimulated results (left), and simulated results evaluated in light of our observed data.\n\n\n\n\n\n\n\nSimulated results (left), and simulated results evaluated in light of our observed data.\n\n\n\n\nYou can play with different configurations of the tea tasting scenario here or here (two links to different servers hosting the same application).\n\n\n\nOur simulation shows that under random chance, it appears that our tea taster would be expected to identify all of the cups correctly (corresponding to HHHH) 4/100 = 0.04 times.\n\n\n\n\n\n\nNote\n\n\n\n0.04 in this example corresponds to our p-value - the probability under the null hypothesis of observing the results from our experiment.\n\n\n0.04 is a fairly low value, so we might say that we don’t believe that the results are sufficiently likely under our null hypothesis. In this case, the probability of observing the results under the null hypothesis is low, so we might instead conclude that the alternative hypothesis seems more reasonable – that is, it is more likely that the null hypothesis is wrong. So, we might instead conclude that because our p-value is so low, that is, that we are unlikely to observe results this extreme under random chance, that instead we believe that the lady is not guessing and can actually detect the difference in tea prepared in different ways. We reject the null hypothesis and conclude that the alternative is more likely.\nNow, in this example, we have a relatively low sample size – which means that it is hard for us to find evidence too much stronger than what our simulation provided for us. In many situations in science, however, we may require stronger evidence that the null hypothesis is unlikely to generate results that we have observed – corresponding to requiring a p-value that is lower than 0.05. The correct threshold value (“alpha”) for rejecting a null hypothesis differs by discipline (physics may use values like \\(10^{-6}\\)) and by the consequences of the results (medical trials may require small p-values, while studies looking for avenues to explore may use higher p-values.)\n\n\n\nThe simulation method described above for evaluating the probability of observing the evidence under the null hypothesis relies on significant manual simulation or outsourcing that work to a computer. The results are not guaranteed to be the same every time, and before computers were common, the manual simulation approach was often too tedious to use regularly. Thus, probability distributions describing the results mathematically were used instead.\n\n\n\nSimulated distributions approximate the theoretical distribution, but connect more clearly to real-world ideas.\n\n\nNo matter what distribution the researcher uses to compare to, the basic idea of theory-based statistics is the same: we look for evidence that our result is (or is not) likely under the null hypothesis. If the result is likely under the null, then we can’t say anything – we can’t disprove the idea that the results are due to chance. If the result isn’t likely under the null, then we reject the null hypothesis and say the alternative is more likely.\nIn theory-based tests, this evidence is usually in the form of a __-value, where the blank is the name of the distribution (commonly, \\(z\\), \\(t\\), \\(F\\), \\(\\chi^2\\)).\n\n\n\nThe same process used in simulated distributions works in theory-based distributions.\n\n\nYou can play with different simulations and distributions here or here (two links to different servers hosting the same application). Use the Distributions tab.\n\n\n\nThe p-value is the probability of observing the data we saw under the null hypothesis \\(H_0\\). A p-value is the area under the reference distribution where values are as or more extreme than the hypothesized value.\n\nIf the p-value is low (\\(p &lt; \\alpha\\), where \\(\\alpha = 0.05, 0.01\\), or another pre-specified value) then we know that it is relatively unlikely to observe our data under \\(H_0\\)… which means that it is more likely that \\(H_0\\) is false and \\(H_A\\) is true.\nWhen p-values are low, we reject \\(H_0\\) and conclude that \\(H_A\\) is more likely.\n\nNot all alternative hypotheses are one sided, e.g. \\(x &gt; a\\). Some hypotheses are two sided - \\(H_0: x = a\\) and \\(H_A: x \\neq a\\). When we have a two-sided hypothesis, we have two areas of our distribution that contribute to the p-value.",
    "crumbs": [
      "Statistics Primer"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU.html#estimating-values-confidence-intervals",
    "href": "Extension/2022-Extension-REU.html#estimating-values-confidence-intervals",
    "title": "Statistics Primer",
    "section": "",
    "text": "Sometimes, we don’t want to test whether a parameter is equal to a specific value - instead, we might want to know what that value is (or at least, a range of possible values for that parameter).\nIn this case, we construct a confidence interval - a set of plausible values for the parameter.\nWe can think of a confidence interval as our best estimate of the parameter value + uncertainty.\n\n\n\nConfidence intervals are a range of values around the central estimate obtained from the sample data\n\n\nConfidence intervals, like hypothesis tests, are conducted based on a parameter \\(\\alpha\\) representing the acceptable level of error. If we want to be 95% confident in our estimate, our interval will be wider than if we want to be 90% confident in our estimate – we have to include more values to get a wider interval.",
    "crumbs": [
      "Statistics Primer"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU.html#experimental-design",
    "href": "Extension/2022-Extension-REU.html#experimental-design",
    "title": "Statistics Primer",
    "section": "",
    "text": "Many studies have a design which is more complicated than the simple examples shown in the previous section. However, all of these designs use the same statistical principles - they may just be applied in different ways.\nWhat follows is a brief description and depiction of how these different experimental designs work in practice. Focus primarily on the way the experiments are set up – in the end, there is always a test statistic computed from the sample mean(s) and variance(s) which is compared to a distribution, as described above.\n\n\n\n\nIn one-sample tests of categorical variables, we typically want to know whether the proportion of successes (the quantity we’re interested in) is equal to a specific value (that is, \\(\\pi = 0.5\\) or something of that sort). Our population parameter, \\(\\pi\\), represents the unknown population quantity, and our sample statistic, \\(\\hat p\\), represents what we know about the value of \\(\\pi\\).\nIn these tests, our null hypothesis is that \\(\\pi = a\\), where a is chosen relative to the problem. Often, \\(a\\) is equal to 0.5, because usually that corresponds to random chance.\nWhen simulating these experiments, we will often use a coin flip (for random chance) or a spinner (for other values of \\(\\pi\\)) to generate data.\nYou can play with different one sample categorical tests here or here (two links to different servers hosting the same application). Use the One Categorical Variable tab.\n\n\n\nOne-sample continuous variable experiments cannot be simulated because we do not usually know the characteristics of the population we’re trying to predict from. Instead, we use theory-based tests for continuous one-sample data.\nYou can play with different one sample continuous tests here or here (two links to different servers hosting the same application). Use the One Continuous Variable tab.\n\n\n\n\n\nIn a two-sample test, there are two groups of participants which are assigned different treatments. The goal is to see how the two treatments differ. Because there are two groups, the mathematical formula for calculating the standardized statistic is slightly more complicated (because the variability of \\(\\overline{X}_A - \\overline{X}_B\\) is a bit more complicated), but in the end that statistic is compared to a similar reference distribution.\n \nYou can play with different two sample categorical tests here or here (two links to different servers hosting the same application). Use the Categorical + Continuous Variable tab.\n\n\n\nIn a variation on this theme, in some cases, we may want to compare two treatments, but we may design the experiment to reduce variability using either repeated measures or matched pairs.\nA repeated measures study requires each participant to experience both treatments in the experiment.\n\n\n\nIn a repeated measures study, the same individuals see both treatment A and treatment B; this way, each individual serves as their own control\n\n\nSometimes, it is not ethical or feasible to give the same individual both treatments – for instance, we cannot ethically or logistically assign mothers to breastfeed or formula feed with the same baby – and so instead, we must create pairs of individuals who are similar.\n\n\n\nIn a matched pairs study, we use covariates to match individuals and then assign each individual in a pair to a single treatment. Matched pairs studies reduce variability, but not as much as repeated measures studies\n\n\nYou can play with different matched-pairs and repeated-measures studies here or here (two links to different servers hosting the same application). Use the One Continuous Variable tab, and the difference between your matched pairs or repeated measures as your observation.\n\n\n\n\nIn other cases, we may be more interested in sources of variability in the data.\n\n\n\nSuppose we have a group of elementary school children, separated by grade. We want to know if grade is a good predictor of the children’s height.\n\n\nIf a variable is important, then it should account for more variability in the data than the overall variability between two observations. In this example, that means that children within a grade should be more similar than children who are from different grades.\n\n\n\nTo get this information, for each group we calculate the group mean\n\n\n\n\n\nThen, for each individual, we calculate the deviation from the group mean\n\n\nANOVA models are sometimes shown in tables like this:\n\n\n\n\n\nFactor\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\ngrade\n2\n112\n56.000000\n26.25\n1.26e-05\n\n\nResiduals\n15\n32\n2.133333\n\n\n\n\nTotal\n17\n144\n\n\n\n\n\n\n\n\nThe overall statistic we calculate is the ratio of the sum-of-squares within groups to the sum-of-squares between groups. The mathematical details of this aren’t that important here, unless they make the process easier to understand.\nBetween group SS: \\(6 * (43.77 - 41)^2 + 6* (43 - 43.77)^2 + 6 * (47 - 43.77)^2 = 42.77 + 2.69 + 66.53 = 112\\)\nWithin group SS: \\[\\left(0^2 + 3^2 + (-1)^2 + 0^2 + (-1)^2 + (-1)^2\\right) + \\\\\n\\left((-1)^2 + (-1)^2 + 2^2 + (-2)^2 + 1^2 + 1^2\\right) + \\\\\n\\left(0^2 + 0^2 + 0^2 + 0^2 + (-2)^2 + 2^2\\right) = 32\\]\nSo by adding the group variable, we reduce our total error from 144 (112 + 32) to 32. Not bad! Put another way, our group variable explains some 77% of the overall variability in the data.\nANOVA models calculate out an F-statistic which is compared to an F-distribution. This F-statistic is calculated as the ratio of the Mean Sq. for each group - the sum of squared errors for each group (between, within) divided by the degrees of freedom (the number of observations - 1). In this case, our F value (with 2, 15 degrees of freedom) is 26.25. This corresponds to a p-value of 0.00001262 – so the chances of observing something this significant when there is in fact no difference between groups is very low.\n\n\n\n\n\nIt is clear that 26.25 is very much in the tails of the F(2, 15) distribution, which explains the extremely low p-value.\n\n\n\n\n\n\n\n\n\n\n\nTwo continuous variables may have a linear relationship\n\n\nIt’s fairly common in science to have two continuous quantitative variables – for instance, height and weight, or fertilizer applied and yield. When we have data like this, we use linear regression to fit a regression line to the data. This line minimizes the errors in \\(y\\), and is sometimes called the least squares regression line.\n\n\n\nWe estimate the linear relationship using the least-squares regression line \\(\\hat{y} = a \\cdot x + b\\), where \\(a\\) is the slope of the line and \\(b\\) is the y-intercept. \\(\\hat y\\) is the predicted value of y at a given value of \\(x\\)\n\n\nGenerally, though, our data are not fixed: they are the result of sampling. If this is the case, then we know that a different sample may provide a different result. Thus, we know that any estimates \\(a\\) and \\(b\\) have variability that directly results from how we collected the data.\n\n\n\nIf we have a different sample, we may get a different regression line – which means \\(a\\) and \\(b\\) have variability (and a corresponding distribution)\n\n\nAs a result, we generally have a distribution of values corresponding to \\(a\\) and a similar distribution of values corresponding to \\(b\\). Because our data are the result of a random sample, we can analyze the least squares regression coefficients using statistical techniques.\nWe may want to test hypotheses about \\(a\\) such as “Is there a relationship between \\(x\\) and \\(y\\)?” (This doesn’t mention \\(a\\), but if there is no relationship between \\(x\\) and \\(y\\), then \\(a\\) would be 0, so implicitly, we’re asking whether \\(a = 0\\).) Typically, scientists aren’t as interested in the value of \\(b\\).\nWe can test these hypotheses using simulation by arranging our data as if there is no relationship between \\(x\\) and \\(y\\) - that is, by shuffling our \\(y\\) data to correspond to a random \\(x\\) value in the dataset. Then, we would fit a new regression line and record the value of \\(a^\\ast\\) (the simulated \\(a\\)).\nJust like before, when we shuffled data or labels, we generate a distribution of \\(a^\\ast\\) under the null hypothesis and compare our observed value to that distribution, counting up the number of values which are more extreme.",
    "crumbs": [
      "Statistics Primer"
    ]
  },
  {
    "objectID": "errors.html",
    "href": "errors.html",
    "title": "Marley, Eddie, and Tulip - A Story About Statistical Decision Making",
    "section": "",
    "text": "Marley, a yellow lab who likes to hitch rides with the local UPS truck, hang around his dad’s shop, and is well trained 90% of the time and wild the other 10%.\n\n\nTulip, a Pekingese who likes to go for walks, get brushed, and hang out with her mom on the couch and read.\nEddie, a Jack Russel Terrier who likes to chase rabbits, destroy stuffed toys, and bark at anyone walking past on the sidewalk."
  },
  {
    "objectID": "errors.html#our-characters",
    "href": "errors.html#our-characters",
    "title": "Marley, Eddie, and Tulip - A Story About Statistical Decision Making",
    "section": "",
    "text": "Marley, a yellow lab who likes to hitch rides with the local UPS truck, hang around his dad’s shop, and is well trained 90% of the time and wild the other 10%.\n\n\nTulip, a Pekingese who likes to go for walks, get brushed, and hang out with her mom on the couch and read.\nEddie, a Jack Russel Terrier who likes to chase rabbits, destroy stuffed toys, and bark at anyone walking past on the sidewalk."
  },
  {
    "objectID": "errors.html#big-decisions",
    "href": "errors.html#big-decisions",
    "title": "Marley, Eddie, and Tulip - A Story About Statistical Decision Making",
    "section": "Big Decisions",
    "text": "Big Decisions\nEddie, Tulip, and Marley are all attending a department picnic where there are games, food, and lots of people who are willing to pet them. While attending this picnic, each dog is interested in investigating objects to decide on the most fundamental question in the universe: is this food?\nMarley prefers to err on the side of “this is definitely food”. Marley once ate an entire can of WD-40 and lived to tell the tale; on another occasion, he ate a length of garden hose, which worked well until the very end when he required some unfortunate assistance from his dad. Essentially, Marley will eat anything - a tennis ball, a hotdog dropped by a toddler, a shoe… it’s all fair game in his world.\nTulip, on the other hand, is very selective. She prefers her canned wet dog food, and isn’t sure that a hot dog is food (but the cheese on her mom’s hamburger definitely is). When it comes to eating, Tulip would prefer to call some food inedible.\nEddie is a bit harder to quantify. When faced with a question of “is this food”, he will chew on the unknown object, leaving it in an inconclusive state of “maybe this is food, but maybe it’s just a toy”."
  },
  {
    "objectID": "Forensics/random-match-prob.html",
    "href": "Forensics/random-match-prob.html",
    "title": "Hands-on (Shoes-off) Probability",
    "section": "",
    "text": "Suppose you are a forensic examiner.\n\nYou’ve been given a crime-scene print as well as a suspect’s shoe, which you have used to make a print comparable to the one found at the crime scene. The images are shown in Figure 1.\n\n\n\n\n\n\n\n\n\n\n\n(a) Print of the suspect’s shoe\n\n\n\n\n\n\n\n\n\n\n\n(b) Crime Scene Print\n\n\n\n\n\n\n\nFigure 1: Evidence specific to the case in question\n\n\n\nCompare the features of the lab-made print and the crime-scene print.\nDo they look similar?\nAre there any differences?\n\nYou’ve determined that the two prints form a class characteristic match - they have sufficiently similar features that the suspect might have left the print at the crime scene, but it could also have been any other person wearing the same model of shoe. You are writing up your report, and you expect you will have to testify in court about whether the suspect did or did not commit the crime. To do this, you need some sort of way to determine how likely it is that a random person off the street is to have the same shoe as the one that left the print at the scene.\n\nConsider for a moment what you would say if the print and the suspect’s shoe had been of a different model, like the Converse Chuck Taylor All-Star shown in Figure 2.\n\n\n\n\n\n\nFigure 2: Converse Chuck Taylor sole\n\n\n\nThese shoes were first introduced in the 1960s and have had a relatively consistent design for 60 years. In addition, many different models of Converse shoes (and several knock-off brands) feature a similar sole pattern, which means it is not possible to determine what model of Converse made a specific print.\nThen, think about what you would say if the print and the suspect’s shoe had been from a shoe with a relatively uncommon pattern, such as the shoe sole shown in Figure 3.\n\n\n\n\n\n\nFigure 3: El Naturalista’s Nido boot sole. The site describes the sole as follows: “The storks nests, to which the same couples return year after year, somewhere to come back to, a stable home and the place where life begins after each laying, are the perfect inspiration for those who seek to return home every day have[sic] enjoyed a unique design and comfort.”\n\n\n\nIf your crime scene print had been from a Converse shoe, does that mean the suspect is more or less likely to be guilty than if the crime scene print had been from a El Naturalista Nido boot like the sole in Figure 3?\n\nDaydreaming over, you start back to your report writing. How do you characterize the types of shoes people wear in the population? What makes a shoe common or uncommon?"
  },
  {
    "objectID": "Forensics/random-match-prob.html#materials",
    "href": "Forensics/random-match-prob.html#materials",
    "title": "Hands-on (Shoes-off) Probability",
    "section": "Materials",
    "text": "Materials\n\nCooking Spray\nChocolate Milk powder\nNote: Cocoa powder used for baking is not ideal for this project. You want something designed to stir into milk.\nWhite printer paper of a size appropriate to your participants’ feet.\n\n8.5” x 14” paper will accommodate most feet. Here is a template that you can use that includes a forensics ruler (Do not scale if you want the measurements to be accurate).\nIf you have a lot of tall men in your sample population, you may need to combine multiple sheets or use 11” x 17” paper.\n\n2 towels, puppy pads, or rolls of paper towels\nA cookie sheet large enough to hold your sheet of paper\n1-2 spoons\ntape (optional - to hang the prints up on the wall)\nA pan filled with about 1” of soapy water (optional - good if doing this indoors)"
  },
  {
    "objectID": "Forensics/random-match-prob.html#directions",
    "href": "Forensics/random-match-prob.html#directions",
    "title": "Hands-on (Shoes-off) Probability",
    "section": "Directions",
    "text": "Directions\nPDF for classroom use\n\nTake off one shoe, hold it sole up, and (lightly) apply cooking spray to the sole.\nSet the shoe on the towel or pad and put it back on. Step/hop on the shoe once or twice to remove excess oil.\nStep (with your oiled shoe) onto the first sheet of paper, rolling heel-to-toe.\nStep (with your oiled shoe) onto the second sheet of paper, rolling heel-to-toe.\nStep into the pan of soapy water with the shoe that you oiled, then step onto the towel to dry your shoe off.\nLightly sprinkle about 1/4 tsp of chocolate milk powder onto each sheet of paper. Shake the sheet of paper to spread the powder around so that it adheres to the oil.\nUse the feature guide to identify different geometric features on your shoe print.\nCompare with other shoe prints - do any have similar features in similar locations?\nNote: This step may only work in groups of about 30 or more.\n\nThe Random Match Probability of a shoe is the number of similar prints divided by the total number of prints. \\[\\hat P_\\text{Random Match} = \\frac{\\# \\text{ similar prints}}{\\text{Total # prints}}\\]\nIf our sample is large enough and representative of the larger population, then our estimated random match probability might be close enough to the hypothetical random match probability in the population"
  },
  {
    "objectID": "Graphics/2023-REU.html",
    "href": "Graphics/2023-REU.html",
    "title": "Creating Good Graphics",
    "section": "",
    "text": "Let’s start out by looking at some examples of less-than-effective charts.\n\n\nSee if you can spot the problem with this one, published in the March 16, 2021 Scottsbluff, NE Star Herald (wtfViz 2021).\n\n\n\n\n\n\n\n\nFigure 1: Scottsbluff Star Herald Reader poll.\n\n\n\n\n\n\nDiscuss:\n\nWhat is wrong with this chart?\nDo you think it might be misleading? If so, how?\nDo you think the mistakes were intentional?\n\n\n\n\n\n\nWhile I didn’t intend this section to have a theme, here’s another chart on a similar topic from CBS News (wtfViz 2022).\n\n\n\n\n\n\nFigure 2: High support.\n\n\n\nDiscuss:\n\nWhat is wrong with this chart?\nWhat would you change to more accurately represent the data?\nDo you think the mistakes were intentional?\n\n\n\n\nPie charts aren’t the only chart type that commonly are presented wrong. Here’s a bar chart that generated a lot of conversation online, from Express Web Desk (2018).\n\n\n\n\n\n\nFigure 3: Gas and Diesel price changes in India (2004 - 2018).\n\n\n\nDiscuss:\n\nWhat is wrong with this?\nWhat design choices contribute to the problems?\nDo you think this was intentionally designed to be misleading? Why or why not?\n\n\n\n\nNot all charts are intentionally designed to be misleading. Sometimes, the desire to show all of the data goes awry. Here is an attempt to show 6 variables using three location variables, color, column length, and column width (Pies 2013). The original source doesn’t specify what variables are plotted, so analyze this based on its’ form, rather than the data it shows.\n\n\n\n\n\n\nFigure 4\n\n\n\nDiscuss:\n\nWhat problems do you have reading this chart?\nCan you compare the quantities of all 6 variables shown? Why or why not?\n\n(Yes, the blog this chart is taken from is satirical. This is not a recommended graphical form.)\nThese are some of my favorite examples, but of course, there are also bad charts in the scientific literature (Broman 2018). The goal of this module is to ensure that as you work on research, you will create effective graphics that are accessible and well-designed.",
    "crumbs": [
      "Creating Good Charts (2023)"
    ]
  },
  {
    "objectID": "Graphics/2023-REU.html#example-1-pie-chart-poll-results",
    "href": "Graphics/2023-REU.html#example-1-pie-chart-poll-results",
    "title": "Creating Good Graphics",
    "section": "",
    "text": "See if you can spot the problem with this one, published in the March 16, 2021 Scottsbluff, NE Star Herald (wtfViz 2021).\n\n\n\n\n\n\n\n\nFigure 1: Scottsbluff Star Herald Reader poll.\n\n\n\n\n\n\nDiscuss:\n\nWhat is wrong with this chart?\nDo you think it might be misleading? If so, how?\nDo you think the mistakes were intentional?",
    "crumbs": [
      "Creating Good Charts (2023)"
    ]
  },
  {
    "objectID": "Graphics/2023-REU.html#example-2-high-support",
    "href": "Graphics/2023-REU.html#example-2-high-support",
    "title": "Creating Good Graphics",
    "section": "",
    "text": "While I didn’t intend this section to have a theme, here’s another chart on a similar topic from CBS News (wtfViz 2022).\n\n\n\n\n\n\nFigure 2: High support.\n\n\n\nDiscuss:\n\nWhat is wrong with this chart?\nWhat would you change to more accurately represent the data?\nDo you think the mistakes were intentional?",
    "crumbs": [
      "Creating Good Charts (2023)"
    ]
  },
  {
    "objectID": "Graphics/2023-REU.html#example-3-gas-prices",
    "href": "Graphics/2023-REU.html#example-3-gas-prices",
    "title": "Creating Good Graphics",
    "section": "",
    "text": "Pie charts aren’t the only chart type that commonly are presented wrong. Here’s a bar chart that generated a lot of conversation online, from Express Web Desk (2018).\n\n\n\n\n\n\nFigure 3: Gas and Diesel price changes in India (2004 - 2018).\n\n\n\nDiscuss:\n\nWhat is wrong with this?\nWhat design choices contribute to the problems?\nDo you think this was intentionally designed to be misleading? Why or why not?",
    "crumbs": [
      "Creating Good Charts (2023)"
    ]
  },
  {
    "objectID": "Graphics/2023-REU.html#example-4-information-overload",
    "href": "Graphics/2023-REU.html#example-4-information-overload",
    "title": "Creating Good Graphics",
    "section": "",
    "text": "Not all charts are intentionally designed to be misleading. Sometimes, the desire to show all of the data goes awry. Here is an attempt to show 6 variables using three location variables, color, column length, and column width (Pies 2013). The original source doesn’t specify what variables are plotted, so analyze this based on its’ form, rather than the data it shows.\n\n\n\n\n\n\nFigure 4\n\n\n\nDiscuss:\n\nWhat problems do you have reading this chart?\nCan you compare the quantities of all 6 variables shown? Why or why not?\n\n(Yes, the blog this chart is taken from is satirical. This is not a recommended graphical form.)\nThese are some of my favorite examples, but of course, there are also bad charts in the scientific literature (Broman 2018). The goal of this module is to ensure that as you work on research, you will create effective graphics that are accessible and well-designed.",
    "crumbs": [
      "Creating Good Charts (2023)"
    ]
  },
  {
    "objectID": "Graphics/2023-REU.html#why-graphics-matter",
    "href": "Graphics/2023-REU.html#why-graphics-matter",
    "title": "Creating Good Graphics",
    "section": "Why Graphics Matter",
    "text": "Why Graphics Matter\nGraphics are a form of external cognition that allow us to think about the data rather than the chart.\nThat is, graphics are a tool to make it easier for us to think about what the data means.\nGood graphics take advantage of how the brain works, leveraging\n\npreattentive processing\nperceptual grouping\nawareness of visual limitations\n\nGood graphics also depend on the data: the chart type should be chosen based on the types of variables you want to display, the amount of data you have, and the results you want to highlight.\n\nExample: Hertzsprung Russell Diagram\nOur first example of a good chart is the Hertzsprung-Russell Diagram (Wikipedia contributors 2023a).\n\n\n\n\n\nThe Hertzsprung Russell diagram. Discovered independently by Ejnar Hertzsprung (1873–1967) and Henry Norris Russell (1877–1957). The diagram plots the color index of the star against the brightness (absolute magnitude) of the star. As a result, it is possible to discern that these two variables are related and change together over a star’s life cycle: a hypothesis that only came to be because of this chart.\n\n\n\n\nJohn Tukey, a famous statistician often considered the father of statistical graphics, wrote in Exploratory Data Analysis (1977):\n\nThe greatest value of a picture is when it forces us to notice what we never expected to see.\n\nThis chart is an excellent example of the value that good graphics create in research: they can help us understand our data in a new way, leading to innovations and new research directions.\nDiscuss:\n\nWhat variables are mapped to the following chart dimensions?\n\nX location\nY location\ncolor\n\nWhat other information is present on the chart that is not specifically a data value?\nWhat does this chart do well?\nWhat design features “work”?\nWhat don’t you like?\n\nI’ve used data from the HYG Database to generate this chart. Only stars within 500 AU are shown.",
    "crumbs": [
      "Creating Good Charts (2023)"
    ]
  },
  {
    "objectID": "Graphics/2023-REU.html#perceptual-principles",
    "href": "Graphics/2023-REU.html#perceptual-principles",
    "title": "Creating Good Graphics",
    "section": "Perceptual Principles",
    "text": "Perceptual Principles\n\nPreattentive Perception\n\nOccurs automatically (no effort)\nColor, shape, angle\nCombinations of preattentive features require attention\n\nDouble-encoding (using multiple features for the same variable) is ok\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Shape\n\n\n\n\n\n\n\n\n\n\n\n(b) Color\n\n\n\n\n\n\n\nFigure 5: Two scatterplots with one point that is different. Can you easily spot the different point?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Shape and Color (dual encoded)\n\n\n\n\n\n\n\n\n\n\n\n(b) Shape and Color (different variables)\n\n\n\n\n\n\n\nFigure 6: Two scatterplots. Can you easily spot the different point(s)?\n\n\n\n\n\nPerceptual Grouping\nPerception is interesting, because when faced with ambiguous images, we can learn something about how our brains work.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Is this a rabbit or a duck?\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nFigure 8: What do you see in this image?\n\n\n\n\n\n\nIn Figure 7, the image is ambiguous, and depending on what orientation we use, the figure can be either a rabbit or a duck. That is, the same image can be interpreted in two different ways, depending on the contextual information we have.\nHow do you describe the components of Figure 8? Something like “Three circles, a black triangle outline, and a white triangle over top?” The components of Figure 8 are 3 pac-man shapes and 3 angles - that’s what’s actually there. The appearance of triangles and depth information is a construction that occurs within the brain.\nOur brains use past experience to simplify the visual input from the world. It’s much easier to describe Figure 8 if you see triangles and circles rather than angles and pac-men shapes.\nThe perceptual rules that describe how we make sense of the world are the Gestalt laws, but the general principle is that the whole is more than the sum of the parts - as in Figure 8, the brain constructs meaning from individual pieces that, when combined, produce greater meaning - for example, a white triangle, a black triangle outline, and 3 circles.\n\nYou can read about the gestalt rules here (Wikipedia contributors 2023b), but they are also demonstrated in the figure above.\nIn graphics, we can leverage the gestalt principles of grouping to create order and meaning. If we color points by another variable, we are creating groups of similar points which assist with the perception of groups instead of individual observations. If we add a trend line, we create the perception that the points are moving “with” the line (in most cases), or occasionally, that the line is dividing up two groups of points. Depending on what features of the data you wish to emphasize, you might choose different aesthetics mappings, facet variables, and factor orders.\n\n\n\n\n\n\nSuppose I want to emphasize the change in the murder rate between 1980 and 2010.\nI could use a bar chart (showing only the first 4 states alphabetically for space), a line chart (showing one line per state), or a box plot (showing variability over time).\n\nRPython\n\n\ntmp &lt;- tempfile(fileext = \".rda\")\ndownload.file(\"https://github.com/heike/classdata/raw/main/data/fbiwide.v2.rda\", destfile = tmp, mode = \"wb\")\nload(tmp)\nfbiwide &lt;- fbiwide.v2\nlibrary(dplyr)\nlibrary(ggplot2)\n\nyearsubset &lt;- filter(fbiwide, year %in% c(1990, 2000, 2010, 2020)) %&gt;%\n  select(state, homicide, population, year, agency_submitting, source) %&gt;%\n  filter(source == \"SRS\")\n\nyearsubset %&gt;%\n  filter(state %in% c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\")) %&gt;%\n  ggplot(aes(x = state, y = homicide/population*100000, fill = factor(year))) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  ylab(\"Homicides per 100,000 residents\")\n\nyearsubset %&gt;%\n  ggplot(aes(x = year, y = homicide/population*100000, group = state)) +\n  geom_line() +\n  xlab(\"Year\") + \n  ylab(\"Homicides per 100,000 residents\")\n\nyearsubset %&gt;%\n  ggplot(aes(x = factor(year), y = homicide/population*100000)) +\n  geom_boxplot() +\n  xlab(\"Year\") + \n  ylab(\"Homicides per 100,000 residents\")\n\n\n\n\n\nBar chart, showing 4 states\n\n\n\n\n\n\n\nLine chart, with one state per line\n\n\n\n\n\n\n\nBox plot by year\n\n\n\n\n\nThree versions of the same data that emphasize different aspects of the dataset.\n\n\n\n\n\nimport pandas as pd\nfrom plotnine import *\n\nfbiwide = r.fbiwide\n\nfbisub = fbiwide[fbiwide.source.isin(['SRS'])]\nfbisub = fbisub.assign(yearfactor = pd.Categorical(fbisub.year))\nfbisub = fbisub.assign(homicide100k = fbisub.homicide/fbisub.population * 100000)\n\nyrsub = fbisub[fbisub.year.isin([1990, 2000, 2010, 2020])]\nyrsub = yrsub.assign(yearfactor = pd.Categorical(yrsub.year))\nstateyrsub = yrsub[yrsub.state.isin([\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"])]\n\n(\nggplot(stateyrsub, aes(x = \"state\", y = \"homicide100k\", fill = \"yearfactor\")) +\n  geom_col(stat='identity', position = \"dodge\") +\n  coord_flip() +\n  ylab(\"Homicides per 100,000 residents\")\n)\n(\nggplot(yrsub, aes(x = \"year\", y = \"homicide100k\", group = \"state\")) +\n  geom_line() +\n  ylab(\"Homicides per 100,000 residents\")\n)\n(\nggplot(yrsub, aes(x = \"yearfactor\", y = \"homicide100k\")) +\n  geom_boxplot() +\n  ylab(\"Homicides per 100,000 residents\")\n)\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\nBar chart, showing 4 states\n\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\nLine chart, with one state per line\n\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\nBox plot by year\n\n\n\n\n\nThree versions of the same data that emphasize different aspects of the dataset.\n\n\n\n\n\n\n\n\n\nWhich one best demonstrates that in every state and region, the murder rate decreased?",
    "crumbs": [
      "Creating Good Charts (2023)"
    ]
  },
  {
    "objectID": "Graphics/2023-REU.html#perceptual-and-visual-limitations",
    "href": "Graphics/2023-REU.html#perceptual-and-visual-limitations",
    "title": "Creating Good Graphics",
    "section": "Perceptual and Visual Limitations",
    "text": "Perceptual and Visual Limitations\nOur perceptual system is not infallible, and some people have additional challenges to work with.\n\nColor\nAbout 10% of the XY population and 0.2% of the XX population has some form of colorblindness or color deficiency.\nHere are some basic tips for choosing color schemes for your charts.\n\nDo not use rainbow color gradient schemes\n\nbecause of the unequal perception of different wavelengths, these schemes are misleading - the color distance does not match the perceptual distance.\n\nAvoid any scheme that uses green-yellow-red signaling if you have a target audience that may include colorblind people.\nTo “colorblind-proof” a graphic, you can use a couple of strategies:\n\ndouble encoding - where you use color, use another aesthetic (line type, shape) as well to help your colorblind readers out\nIf you can print your chart out in black and white and still read it, it will be safe for colorblind users. This is the only foolproof way to do it!\nIf you are using a color gradient, use a monochromatic color scheme where possible. This is perceived as light -&gt; dark by colorblind people, so it will be correctly perceived no matter what color you use.\nIf you have a bidirectional scale (e.g. showing positive and negative values), the safest scheme to use is purple - white - orange. In any color scale that is multi-hue, it is important to transition through white, instead of from one color to another directly.\n\nBe conscious of what certain colors “mean”\n\nLeveraging common associations can make it easier to read a color scale and remember what it stands for (e.g. blue for cold, orange/red for hot is a natural scale, red = Republican and blue = Democrat in the US, white -&gt; blue gradients for showing rainfall totals)\nSome colors can can provoke emotional responses that may not be desirable.1\nIt is also important to be conscious of the social baggage that certain color schemes may have - the pink/blue color scheme often used to denote gender can be unnecessarily polarizing, and it may be easier to use a colder color (blue or purple) for men and a warmer color (yellow, orange, lighter green) for women2.\n\n\n\n\nWorking Memory\nWe can hold about 7 items in “working memory” and maintain these by rehearsing the content. As a result, using a legend with more than 7 items will create additional cognitive load on those viewing the visualizations. Wherever possible, keep cognitive limitations in mind\n\n\nAlt Text and Accessibility\nSome individuals may have limited vision or visual processing ability. To make your charts accessible, you should always provide alt-text for your graphics.\nIt can also help to use larger text size and/or fonts that are easier to read for individuals with e.g. dyslexia (Zorzi et al. 2012). You can customize your charts to make these changes, though instructions will vary based on which plotting system you are using.",
    "crumbs": [
      "Creating Good Charts (2023)"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Teaching Materials",
    "section": "",
    "text": "This github project contains links to various teaching materials I have created and presented that aren’t big enough to justify their own book/separate website.\nHands-on (Shoes-off) Probability - An introduction to probability in forensics with shoe prints.\n2023 REU - Creating Good Charts (pdf)\n2022 Extension REU - Statistics with Cartoons and slides"
  },
  {
    "objectID": "graphics.html",
    "href": "graphics.html",
    "title": "Graphics Projects",
    "section": "",
    "text": "2023 REU - Creating Good Charts (pdf)\n\n\nOther links\n\nStatistical Computing with R and Python",
    "crumbs": [
      "Graphics Projects"
    ]
  },
  {
    "objectID": "Graphics/2024-REU.html",
    "href": "Graphics/2024-REU.html",
    "title": "Creating Good Graphics",
    "section": "",
    "text": "Let’s start out by looking at some examples of less-than-effective charts.\n\n\nSee if you can spot the problem with this one, published in the March 16, 2021 Scottsbluff, NE Star Herald (wtfViz 2021).\n\n\n\n\n\n\n\n\nFigure 1: Scottsbluff Star Herald Reader poll.\n\n\n\n\n\n\nDiscuss:\n\nWhat is wrong with this chart?\nDo you think it might be misleading? If so, how?\nDo you think the mistakes were intentional?\n\n\n\n\n\n\nWhile I didn’t intend this section to have a theme, here’s another chart on a similar topic from CBS News (wtfViz 2022).\n\n\n\n\n\n\nFigure 2: High support.\n\n\n\nDiscuss:\n\nWhat is wrong with this chart?\nWhat would you change to more accurately represent the data?\nDo you think the mistakes were intentional?\n\n\n\n\nPie charts aren’t the only chart type that commonly are presented wrong. Here’s a bar chart that generated a lot of conversation online, from Express Web Desk (2018).\n\n\n\n\n\n\nFigure 3: Gas and Diesel price changes in India (2004 - 2018).\n\n\n\nDiscuss:\n\nWhat is wrong with this?\nWhat design choices contribute to the problems?\nDo you think this was intentionally designed to be misleading? Why or why not?\n\n\n\n\nNot all charts are intentionally designed to be misleading. Sometimes, the desire to show all of the data goes awry. Here is an attempt to show 6 variables using three location variables, color, column length, and column width (Pies 2013). The original source doesn’t specify what variables are plotted, so analyze this based on its’ form, rather than the data it shows.\n\n\n\n\n\n\nFigure 4\n\n\n\nDiscuss:\n\nWhat problems do you have reading this chart?\nCan you compare the quantities of all 6 variables shown? Why or why not?\n\n(Yes, the blog this chart is taken from is satirical. This is not a recommended graphical form.)\nThese are some of my favorite examples, but of course, there are also bad charts in the scientific literature (Broman 2018). The goal of this module is to ensure that as you work on research, you will create effective graphics that are accessible and well-designed.",
    "crumbs": [
      "Creating Good Charts (2024)"
    ]
  },
  {
    "objectID": "Graphics/2024-REU.html#example-1-pie-chart-poll-results",
    "href": "Graphics/2024-REU.html#example-1-pie-chart-poll-results",
    "title": "Creating Good Graphics",
    "section": "",
    "text": "See if you can spot the problem with this one, published in the March 16, 2021 Scottsbluff, NE Star Herald (wtfViz 2021).\n\n\n\n\n\n\n\n\nFigure 1: Scottsbluff Star Herald Reader poll.\n\n\n\n\n\n\nDiscuss:\n\nWhat is wrong with this chart?\nDo you think it might be misleading? If so, how?\nDo you think the mistakes were intentional?",
    "crumbs": [
      "Creating Good Charts (2024)"
    ]
  },
  {
    "objectID": "Graphics/2024-REU.html#example-2-high-support",
    "href": "Graphics/2024-REU.html#example-2-high-support",
    "title": "Creating Good Graphics",
    "section": "",
    "text": "While I didn’t intend this section to have a theme, here’s another chart on a similar topic from CBS News (wtfViz 2022).\n\n\n\n\n\n\nFigure 2: High support.\n\n\n\nDiscuss:\n\nWhat is wrong with this chart?\nWhat would you change to more accurately represent the data?\nDo you think the mistakes were intentional?",
    "crumbs": [
      "Creating Good Charts (2024)"
    ]
  },
  {
    "objectID": "Graphics/2024-REU.html#example-3-gas-prices",
    "href": "Graphics/2024-REU.html#example-3-gas-prices",
    "title": "Creating Good Graphics",
    "section": "",
    "text": "Pie charts aren’t the only chart type that commonly are presented wrong. Here’s a bar chart that generated a lot of conversation online, from Express Web Desk (2018).\n\n\n\n\n\n\nFigure 3: Gas and Diesel price changes in India (2004 - 2018).\n\n\n\nDiscuss:\n\nWhat is wrong with this?\nWhat design choices contribute to the problems?\nDo you think this was intentionally designed to be misleading? Why or why not?",
    "crumbs": [
      "Creating Good Charts (2024)"
    ]
  },
  {
    "objectID": "Graphics/2024-REU.html#example-4-information-overload",
    "href": "Graphics/2024-REU.html#example-4-information-overload",
    "title": "Creating Good Graphics",
    "section": "",
    "text": "Not all charts are intentionally designed to be misleading. Sometimes, the desire to show all of the data goes awry. Here is an attempt to show 6 variables using three location variables, color, column length, and column width (Pies 2013). The original source doesn’t specify what variables are plotted, so analyze this based on its’ form, rather than the data it shows.\n\n\n\n\n\n\nFigure 4\n\n\n\nDiscuss:\n\nWhat problems do you have reading this chart?\nCan you compare the quantities of all 6 variables shown? Why or why not?\n\n(Yes, the blog this chart is taken from is satirical. This is not a recommended graphical form.)\nThese are some of my favorite examples, but of course, there are also bad charts in the scientific literature (Broman 2018). The goal of this module is to ensure that as you work on research, you will create effective graphics that are accessible and well-designed.",
    "crumbs": [
      "Creating Good Charts (2024)"
    ]
  },
  {
    "objectID": "Graphics/2024-REU.html#why-graphics-matter",
    "href": "Graphics/2024-REU.html#why-graphics-matter",
    "title": "Creating Good Graphics",
    "section": "Why Graphics Matter",
    "text": "Why Graphics Matter\nGraphics are a form of external cognition that allow us to think about the data rather than the chart.\nThat is, graphics are a tool to make it easier for us to think about what the data means.\nGood graphics take advantage of how the brain works, leveraging\n\npreattentive processing\nperceptual grouping\nawareness of visual limitations\n\nGood graphics also depend on the data: the chart type should be chosen based on the types of variables you want to display, the amount of data you have, and the results you want to highlight.\n\nExample: Hertzsprung Russell Diagram\nOur first example of a good chart is the Hertzsprung-Russell Diagram (Wikipedia contributors 2023a).\n\n\n\n\n\nThe Hertzsprung Russell diagram. Discovered independently by Ejnar Hertzsprung (1873–1967) and Henry Norris Russell (1877–1957). The diagram plots the color index of the star against the brightness (absolute magnitude) of the star. As a result, it is possible to discern that these two variables are related and change together over a star’s life cycle: a hypothesis that only came to be because of this chart.\n\n\n\n\nJohn Tukey, a famous statistician often considered the father of statistical graphics, wrote in Exploratory Data Analysis (1977):\n\nThe greatest value of a picture is when it forces us to notice what we never expected to see.\n\nThis chart is an excellent example of the value that good graphics create in research: they can help us understand our data in a new way, leading to innovations and new research directions.\nDiscuss:\n\nWhat variables are mapped to the following chart dimensions?\n\nX location\nY location\ncolor\n\nWhat other information is present on the chart that is not specifically a data value?\nWhat does this chart do well?\nWhat design features “work”?\nWhat don’t you like?\n\nI’ve used data from the HYG Database to generate this chart. Only stars within 500 AU are shown.",
    "crumbs": [
      "Creating Good Charts (2024)"
    ]
  },
  {
    "objectID": "Graphics/2024-REU.html#perceptual-principles",
    "href": "Graphics/2024-REU.html#perceptual-principles",
    "title": "Creating Good Graphics",
    "section": "Perceptual Principles",
    "text": "Perceptual Principles\n\nPreattentive Perception\n\nOccurs automatically (no effort)\nColor, shape, angle\nCombinations of preattentive features require attention\n\nDouble-encoding (using multiple features for the same variable) is ok\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Shape\n\n\n\n\n\n\n\n\n\n\n\n(b) Color\n\n\n\n\n\n\n\nFigure 5: Two scatterplots with one point that is different. Can you easily spot the different point?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Shape and Color (dual encoded)\n\n\n\n\n\n\n\n\n\n\n\n(b) Shape and Color (different variables)\n\n\n\n\n\n\n\nFigure 6: Two scatterplots. Can you easily spot the different point(s)?\n\n\n\n\n\nPerceptual Grouping\nPerception is interesting, because when faced with ambiguous images, we can learn something about how our brains work.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Is this a rabbit or a duck?\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nFigure 8: What do you see in this image?\n\n\n\n\n\n\nIn Figure 7, the image is ambiguous, and depending on what orientation we use, the figure can be either a rabbit or a duck. That is, the same image can be interpreted in two different ways, depending on the contextual information we have.\nHow do you describe the components of Figure 8? Something like “Three circles, a black triangle outline, and a white triangle over top?” The components of Figure 8 are 3 pac-man shapes and 3 angles - that’s what’s actually there. The appearance of triangles and depth information is a construction that occurs within the brain.\nOur brains use past experience to simplify the visual input from the world. It’s much easier to describe Figure 8 if you see triangles and circles rather than angles and pac-men shapes.\nThe perceptual rules that describe how we make sense of the world are the Gestalt laws, but the general principle is that the whole is more than the sum of the parts - as in Figure 8, the brain constructs meaning from individual pieces that, when combined, produce greater meaning - for example, a white triangle, a black triangle outline, and 3 circles.\n\nYou can read about the gestalt rules here (Wikipedia contributors 2023b), but they are also demonstrated in the figure above.\nIn graphics, we can leverage the gestalt principles of grouping to create order and meaning. If we color points by another variable, we are creating groups of similar points which assist with the perception of groups instead of individual observations. If we add a trend line, we create the perception that the points are moving “with” the line (in most cases), or occasionally, that the line is dividing up two groups of points. Depending on what features of the data you wish to emphasize, you might choose different aesthetics mappings, facet variables, and factor orders.\n\n\n\n\n\n\nSuppose I want to emphasize the change in the murder rate between 1980 and 2010.\nI could use a bar chart (showing only the first 4 states alphabetically for space), a line chart (showing one line per state), or a box plot (showing variability over time).\n\nRPython\n\n\ntmp &lt;- tempfile(fileext = \".rda\")\ndownload.file(\"https://github.com/heike/classdata/raw/main/data/fbiwide.v2.rda\", destfile = tmp, mode = \"wb\")\nload(tmp)\nfbiwide &lt;- fbiwide.v2\nlibrary(dplyr)\nlibrary(ggplot2)\n\nyearsubset &lt;- filter(fbiwide, year %in% c(1990, 2000, 2010, 2020)) %&gt;%\n  select(state, homicide, population, year, agency_submitting, source) %&gt;%\n  filter(source == \"SRS\")\n\nyearsubset %&gt;%\n  filter(state %in% c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\")) %&gt;%\n  ggplot(aes(x = state, y = homicide/population*100000, fill = factor(year))) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  ylab(\"Homicides per 100,000 residents\")\n\nyearsubset %&gt;%\n  ggplot(aes(x = year, y = homicide/population*100000, group = state)) +\n  geom_line() +\n  xlab(\"Year\") + \n  ylab(\"Homicides per 100,000 residents\")\n\nyearsubset %&gt;%\n  ggplot(aes(x = factor(year), y = homicide/population*100000)) +\n  geom_boxplot() +\n  xlab(\"Year\") + \n  ylab(\"Homicides per 100,000 residents\")\n\n\n\n\n\nBar chart, showing 4 states\n\n\n\n\n\n\n\nLine chart, with one state per line\n\n\n\n\n\n\n\nBox plot by year\n\n\n\n\n\nThree versions of the same data that emphasize different aspects of the dataset.\n\n\n\n\n\nimport pandas as pd\nfrom plotnine import *\n\nfbiwide = r.fbiwide\n\nfbisub = fbiwide[fbiwide.source.isin(['SRS'])]\nfbisub = fbisub.assign(yearfactor = pd.Categorical(fbisub.year))\nfbisub = fbisub.assign(homicide100k = fbisub.homicide/fbisub.population * 100000)\n\nyrsub = fbisub[fbisub.year.isin([1990, 2000, 2010, 2020])]\nyrsub = yrsub.assign(yearfactor = pd.Categorical(yrsub.year))\nstateyrsub = yrsub[yrsub.state.isin([\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"])]\n\n(\nggplot(stateyrsub, aes(x = \"state\", y = \"homicide100k\", fill = \"yearfactor\")) +\n  geom_col(stat='identity', position = \"dodge\") +\n  coord_flip() +\n  ylab(\"Homicides per 100,000 residents\")\n)\n(\nggplot(yrsub, aes(x = \"year\", y = \"homicide100k\", group = \"state\")) +\n  geom_line() +\n  ylab(\"Homicides per 100,000 residents\")\n)\n(\nggplot(yrsub, aes(x = \"yearfactor\", y = \"homicide100k\")) +\n  geom_boxplot() +\n  ylab(\"Homicides per 100,000 residents\")\n)\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\nBar chart, showing 4 states\n\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\nLine chart, with one state per line\n\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\nBox plot by year\n\n\n\n\n\nThree versions of the same data that emphasize different aspects of the dataset.\n\n\n\n\n\n\n\n\n\nWhich one best demonstrates that in every state and region, the murder rate decreased?",
    "crumbs": [
      "Creating Good Charts (2024)"
    ]
  },
  {
    "objectID": "Graphics/2024-REU.html#perceptual-and-visual-limitations",
    "href": "Graphics/2024-REU.html#perceptual-and-visual-limitations",
    "title": "Creating Good Graphics",
    "section": "Perceptual and Visual Limitations",
    "text": "Perceptual and Visual Limitations\nOur perceptual system is not infallible, and some people have additional challenges to work with.\n\nColor\nAbout 10% of the XY population and 0.2% of the XX population has some form of colorblindness or color deficiency.\nHere are some basic tips for choosing color schemes for your charts.\n\nDo not use rainbow color gradient schemes\n\nbecause of the unequal perception of different wavelengths, these schemes are misleading - the color distance does not match the perceptual distance.\n\nAvoid any scheme that uses green-yellow-red signaling if you have a target audience that may include colorblind people.\nTo “colorblind-proof” a graphic, you can use a couple of strategies:\n\ndouble encoding - where you use color, use another aesthetic (line type, shape) as well to help your colorblind readers out\nIf you can print your chart out in black and white and still read it, it will be safe for colorblind users. This is the only foolproof way to do it!\nIf you are using a color gradient, use a monochromatic color scheme where possible. This is perceived as light -&gt; dark by colorblind people, so it will be correctly perceived no matter what color you use.\nIf you have a bidirectional scale (e.g. showing positive and negative values), the safest scheme to use is purple - white - orange. In any color scale that is multi-hue, it is important to transition through white, instead of from one color to another directly.\n\nBe conscious of what certain colors “mean”\n\nLeveraging common associations can make it easier to read a color scale and remember what it stands for (e.g. blue for cold, orange/red for hot is a natural scale, red = Republican and blue = Democrat in the US, white -&gt; blue gradients for showing rainfall totals)\nSome colors can can provoke emotional responses that may not be desirable.1\nIt is also important to be conscious of the social baggage that certain color schemes may have - the pink/blue color scheme often used to denote gender can be unnecessarily polarizing, and it may be easier to use a colder color (blue or purple) for men and a warmer color (yellow, orange, lighter green) for women2.\n\n\n\n\nWorking Memory\nWe can hold about 7 items in “working memory” and maintain these by rehearsing the content. As a result, using a legend with more than 7 items will create additional cognitive load on those viewing the visualizations. Wherever possible, keep cognitive limitations in mind\n\n\nAlt Text and Accessibility\nSome individuals may have limited vision or visual processing ability. To make your charts accessible, you should always provide alt-text for your graphics.\nIt can also help to use larger text size and/or fonts that are easier to read for individuals with e.g. dyslexia (Zorzi et al. 2012). You can customize your charts to make these changes, though instructions will vary based on which plotting system you are using.",
    "crumbs": [
      "Creating Good Charts (2024)"
    ]
  },
  {
    "objectID": "extension.html",
    "href": "extension.html",
    "title": "Extension Projects",
    "section": "",
    "text": "Adapted Primary Literature\nStatistics primer for high school teachers adapting scientific papers to use in high school courses.\n\nBook\nApplet\nSlides\n\n2022 REU\n\nMaterial\nSlides",
    "crumbs": [
      "Extension Projects"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#what-is-statistics",
    "href": "Extension/2022-Extension-REU-slides.html#what-is-statistics",
    "title": "A Short Overview of Statistics",
    "section": "What is Statistics?",
    "text": "What is Statistics?\n\nThe science of developing and studying methods for collecting, analyzing, interpreting, and presenting empirical data\n\n\n\n\nHow should I conduct my experiment?\nWhat is the best way to test my hypothesis?\nWhat is the true value of ____\n(and how precisely do I know that value)?\nWhat does my experiment/sample tell me about my data?\nWhat is the future value of ____ given what I know now?",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#statistical-tasks",
    "href": "Extension/2022-Extension-REU-slides.html#statistical-tasks",
    "title": "A Short Overview of Statistics",
    "section": "Statistical Tasks",
    "text": "Statistical Tasks\nDescription: What does the data say?",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#statistical-tasks-1",
    "href": "Extension/2022-Extension-REU-slides.html#statistical-tasks-1",
    "title": "A Short Overview of Statistics",
    "section": "Statistical Tasks",
    "text": "Statistical Tasks\nExperimental Design: What’s the best way to collect data?",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#statistical-tasks-2",
    "href": "Extension/2022-Extension-REU-slides.html#statistical-tasks-2",
    "title": "A Short Overview of Statistics",
    "section": "Statistical Tasks",
    "text": "Statistical Tasks\nInference: What does the data tell us (about the population)?",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#statistical-tasks-3",
    "href": "Extension/2022-Extension-REU-slides.html#statistical-tasks-3",
    "title": "A Short Overview of Statistics",
    "section": "Statistical Tasks",
    "text": "Statistical Tasks\nPrediction: What will happen next?",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#an-historical-example",
    "href": "Extension/2022-Extension-REU-slides.html#an-historical-example",
    "title": "A Short Overview of Statistics",
    "section": "An Historical Example",
    "text": "An Historical Example\nThe Logic of Hypothesis Testing\n\nCan someone tell whether tea or milk is added first to a cup?\n\n4 cups of tea with milk first  , 4 cups of tea with tea first  \nRandomize the order\nTest the cups and make predictions for all 8 cups\n\n\nWhat is the probability that someone gets all 8 correct?",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#a-lady-tasting-tea",
    "href": "Extension/2022-Extension-REU-slides.html#a-lady-tasting-tea",
    "title": "A Short Overview of Statistics",
    "section": "A Lady Tasting Tea",
    "text": "A Lady Tasting Tea\n\nIf the 4 milk-first cups   are correctly identified, so are the 4 tea-first cups  \nIf we assume the taster is just guessing, we could just as easily flip 4 coins",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#a-lady-tasting-tea-1",
    "href": "Extension/2022-Extension-REU-slides.html#a-lady-tasting-tea-1",
    "title": "A Short Overview of Statistics",
    "section": "A Lady Tasting Tea",
    "text": "A Lady Tasting Tea\n\nStatistical evaluation\n\n\nNull hypothesis: Taster is guessing\n\nIf our experimental results are likely to occur by random chance, we can’t really say whether the taster is guessing or not\n  We fail to reject the null hypothesis\nIf our experimental results are not likely to occur by random chance, we may decide it’s more likely that there is another explanation… the taster knows their stuff!",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#try-it-out",
    "href": "Extension/2022-Extension-REU-slides.html#try-it-out",
    "title": "A Short Overview of Statistics",
    "section": "Try it out!",
    "text": "Try it out!\nGo to https://shiny.srvanderplas.com/APL and start with the Tea Tasting tab.\n\nWhat effect does the # simulations have on the results?\nWhat effect does the # test cups have on the results?\n\nAssuming the number of observed cups is the same as the number of test cups\nAssuming the number of observed cups is less than the number of test cups\n\n\n\n\nAnother link to the same applet is https://srvanderplas.shinyapps.io/UNL-APL-workshop/",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#hypothesis-testing-logic",
    "href": "Extension/2022-Extension-REU-slides.html#hypothesis-testing-logic",
    "title": "A Short Overview of Statistics",
    "section": "Hypothesis Testing Logic",
    "text": "Hypothesis Testing Logic\n\n\n\nRun an experiment and generate an observed value\nSimulate a large number of experiments under random chance (the null hypothesis)\nCompare the observed value to the results of the simulated experiments\nDecide whether the observed value is plausible under random chance, or it is more likely that the results would happen if the null hypothesis is wrong",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#theory-based-statistics",
    "href": "Extension/2022-Extension-REU-slides.html#theory-based-statistics",
    "title": "A Short Overview of Statistics",
    "section": "Theory-based Statistics",
    "text": "Theory-based Statistics\n\n\n\nRun an experiment and generate a test statistic (t, z, F, \\(\\chi^2\\))\nCompare the observed value to the theoretical distribution\nDecide whether the observed value is plausible under random chance, or it is more likely that the results would happen if the null hypothesis is wrong",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#try-it-out-1",
    "href": "Extension/2022-Extension-REU-slides.html#try-it-out-1",
    "title": "A Short Overview of Statistics",
    "section": "Try it out",
    "text": "Try it out\nGo to https://shiny.srvanderplas.com/APL and start with the Distributions tab.\n\nWhat changes when you change distribution?\nHow many samples do you need for the simulation histogram to look similar to the theoretical distribution?\nWhat effect does setting your observed value to be larger have on the p-value?\nNote: At this point, we are doing tests examining values greater than the observed value. This will obviously not always hold true.\nHow different is the simulation p-value from the theoretical p-value? Does this change when you increase the number of samples?",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#statistical-test-logic",
    "href": "Extension/2022-Extension-REU-slides.html#statistical-test-logic",
    "title": "A Short Overview of Statistics",
    "section": "Statistical Test Logic",
    "text": "Statistical Test Logic\n\nGoal: Are the experiment results are compatible with the null hypothesis?\nif the region that is “more extreme” than the observed value is very small, then the experimental results are surprising\n\nThis suggests the null hypothesis might not be reliable\nReject \\(H_0\\) in favor of the alternative",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#statistical-test-logic-1",
    "href": "Extension/2022-Extension-REU-slides.html#statistical-test-logic-1",
    "title": "A Short Overview of Statistics",
    "section": "Statistical Test Logic",
    "text": "Statistical Test Logic",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#statistical-test-logic-2",
    "href": "Extension/2022-Extension-REU-slides.html#statistical-test-logic-2",
    "title": "A Short Overview of Statistics",
    "section": "Statistical Test Logic",
    "text": "Statistical Test Logic\n\nthe region that is “more extreme” than the observed value is summarized as the p-value – the area of that region.\n\np-values lower than \\(\\alpha = 0.05\\), a pre-specified cutoff are considered “statistically significant”\nthat is, they should lead to a rejection of the null hypothesis",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#two-sided-tests",
    "href": "Extension/2022-Extension-REU-slides.html#two-sided-tests",
    "title": "A Short Overview of Statistics",
    "section": "Two Sided Tests",
    "text": "Two Sided Tests\n\nIf we don’t know/care whether \\(x &lt; a\\) or \\(x &gt; a\\), we use a two-sided test\n\n\nYou can experiment with two-sided tests here:\nhttps://shiny.srvanderplas.com/APL/ and click on “One Continuous Variable”",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#confidence-intervals",
    "href": "Extension/2022-Extension-REU-slides.html#confidence-intervals",
    "title": "A Short Overview of Statistics",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nAnother way to use statistics is to get a range of “plausible” values based on the estimate + variability\nThis is called a confidence interval",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#confidence-intervals-1",
    "href": "Extension/2022-Extension-REU-slides.html#confidence-intervals-1",
    "title": "A Short Overview of Statistics",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nEvery confidence interval has a “level” of \\(1-\\alpha\\), just like every hypothesis test has a significance level \\(\\alpha\\)\nConfidence intervals with higher levels (e.g. .99 instead of .95) are wider\nInterval width depends on\n\nsample size\nvariability\nconfidence level\n\nA CI of (A, B) is read as “We are 95% confident that the true value of _________ lies between A and B”",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#one-categorical-variable",
    "href": "Extension/2022-Extension-REU-slides.html#one-categorical-variable",
    "title": "A Short Overview of Statistics",
    "section": "One Categorical Variable",
    "text": "One Categorical Variable\n\nStatistic: # Successes (out of # Trials)\nSimulation method: Flip coins \\((p = 0.5)\\), weighted spinners \\((p\\neq 0.5)\\)\nTheoretical distribution: Binomial\n\nhttps://shiny.srvanderplas.com/APL/ and click on “One Categorical Variable”",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#one-continuous-variable",
    "href": "Extension/2022-Extension-REU-slides.html#one-continuous-variable",
    "title": "A Short Overview of Statistics",
    "section": "One Continuous Variable",
    "text": "One Continuous Variable\n\nStatistic: \\(\\displaystyle t = \\frac{\\overline x - \\mu}{s/\\sqrt{n}}\\) where\n\n\\(\\overline x\\) is the sample mean,\n\\(s\\) is the sample standard deviation,\n\\(\\mu\\) is the hypothesized mean, and\n\\(n\\) is the sample size\n\nSimulation method: none\nTheoretical distribution: \\(t\\) with \\(n-1\\) degrees of freedom\n\nhttps://shiny.srvanderplas.com/APL/ and click on “One Continuous Variable”",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#two-group-tests",
    "href": "Extension/2022-Extension-REU-slides.html#two-group-tests",
    "title": "A Short Overview of Statistics",
    "section": "Two-group Tests",
    "text": "Two-group Tests\n\nCategorical variable: Group 1 or Group 2?\nContinuous variable: Some measurement\nStatistic: \\(\\overline x_1 - \\overline x_2\\)\nSimulation method: shuffle group labels\nTheoretical distribution: \\(t\\)\n(degrees of freedom are a bit complicated)\n\nhttps://shiny.srvanderplas.com/APL/ and click on “Categorical + Continuous Variables”",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#two-group-tests-1",
    "href": "Extension/2022-Extension-REU-slides.html#two-group-tests-1",
    "title": "A Short Overview of Statistics",
    "section": "Two-group Tests",
    "text": "Two-group Tests\n\nA two-sample experiment randomly divides up a sample of experimental units into two groups and calculates the sample mean for each group.",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#two-group-tests-2",
    "href": "Extension/2022-Extension-REU-slides.html#two-group-tests-2",
    "title": "A Short Overview of Statistics",
    "section": "Two-group Tests",
    "text": "Two-group Tests\n\nA two-sample experiment randomly divides up a sample of experimental units into two groups and calculates the sample mean for each group.We compare \\(\\overline{X}_A\\) and \\(\\overline {X}_B\\): \\(\\overline{X}_A - \\overline{X}_B\\).\nThe standard deviation of \\(\\overline{X}_A - \\overline{X}_B\\) requires calculation: Use a two-sample test.",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#repeated-measures",
    "href": "Extension/2022-Extension-REU-slides.html#repeated-measures",
    "title": "A Short Overview of Statistics",
    "section": "Repeated Measures",
    "text": "Repeated Measures",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#repeated-measures-1",
    "href": "Extension/2022-Extension-REU-slides.html#repeated-measures-1",
    "title": "A Short Overview of Statistics",
    "section": "Repeated Measures",
    "text": "Repeated Measures",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#matched-pairs",
    "href": "Extension/2022-Extension-REU-slides.html#matched-pairs",
    "title": "A Short Overview of Statistics",
    "section": "Matched Pairs",
    "text": "Matched Pairs",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#matched-pairs-1",
    "href": "Extension/2022-Extension-REU-slides.html#matched-pairs-1",
    "title": "A Short Overview of Statistics",
    "section": "Matched Pairs",
    "text": "Matched Pairs",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#matched-pairs-2",
    "href": "Extension/2022-Extension-REU-slides.html#matched-pairs-2",
    "title": "A Short Overview of Statistics",
    "section": "Matched Pairs",
    "text": "Matched Pairs",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#matched-pairs-3",
    "href": "Extension/2022-Extension-REU-slides.html#matched-pairs-3",
    "title": "A Short Overview of Statistics",
    "section": "Matched Pairs",
    "text": "Matched Pairs",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#analysis-of-variance",
    "href": "Extension/2022-Extension-REU-slides.html#analysis-of-variance",
    "title": "A Short Overview of Statistics",
    "section": "Analysis of Variance",
    "text": "Analysis of Variance\n\nUsed for multiple groups\n\nSuppose we have a group of schoolchildren separated by grade, and we want to examine the relationship between grade and height.",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#analysis-of-variance-1",
    "href": "Extension/2022-Extension-REU-slides.html#analysis-of-variance-1",
    "title": "A Short Overview of Statistics",
    "section": "Analysis of Variance",
    "text": "Analysis of Variance\n\nIf height is important, students in a single grade should be more similar than students across different grades.",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#analysis-of-variance-2",
    "href": "Extension/2022-Extension-REU-slides.html#analysis-of-variance-2",
    "title": "A Short Overview of Statistics",
    "section": "Analysis of Variance",
    "text": "Analysis of Variance\nGoal: determine similarity within groups\n\nwithin-groups sum-of-squares\nSquare the deviations from the group mean and add them up\nbetween-groups sum-of-squares\nSum of squared differences of the class average and the overall average for each student",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#analysis-of-variance-3",
    "href": "Extension/2022-Extension-REU-slides.html#analysis-of-variance-3",
    "title": "A Short Overview of Statistics",
    "section": "Analysis of Variance",
    "text": "Analysis of Variance\nResults from ANOVA are shown in tables like this:\n\n\n\n\n\nFactor\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\ngrade\n2\n112\n56.000000\n26.25\n1.26e-05\n\n\nResiduals\n15\n32\n2.133333\n\n\n\n\nTotal\n17\n144\n\n\n\n\n\n\n\n\nThe F-value is the statistic, and is compared to an F(df1, df2) distribution - in this case, F(2, 15) to get a p-value.",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#two-continuous-variables",
    "href": "Extension/2022-Extension-REU-slides.html#two-continuous-variables",
    "title": "A Short Overview of Statistics",
    "section": "Two Continuous Variables",
    "text": "Two Continuous Variables\n\nWe want to know if there is a linear association between x and y",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#two-continuous-variables-1",
    "href": "Extension/2022-Extension-REU-slides.html#two-continuous-variables-1",
    "title": "A Short Overview of Statistics",
    "section": "Two Continuous Variables",
    "text": "Two Continuous Variables\n\nIf the slope of the line is nonzero, there is a linear association",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#two-continuous-variables-2",
    "href": "Extension/2022-Extension-REU-slides.html#two-continuous-variables-2",
    "title": "A Short Overview of Statistics",
    "section": "Two Continuous Variables",
    "text": "Two Continuous Variables\n\nWe need to test whether that slope is significantly different from 0",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  },
  {
    "objectID": "Extension/2022-Extension-REU-slides.html#two-continuous-variables-3",
    "href": "Extension/2022-Extension-REU-slides.html#two-continuous-variables-3",
    "title": "A Short Overview of Statistics",
    "section": "Two Continuous Variables",
    "text": "Two Continuous Variables\n\nContinuous variables: \\(x\\) and \\(y\\)\nStatistic: \\(a\\), the sample slope\nSimulation method: shuffle values of \\(y\\) relative to \\(x\\)\nTheoretical distribution: \\(t_{n-2}\\), where \\(n\\) is the number of observations",
    "crumbs": [
      "A Short Overview of Statistics"
    ]
  }
]